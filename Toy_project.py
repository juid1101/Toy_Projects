# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XR8Wc_B0riwjrhPe0s4SFBbJC6STYtQG
"""

!pip install requests beautifulsoup4 pandas openpyxl

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from datetime import datetime
from google.colab import files

# ==========================================
# 1. [ê¸°ëŠ¥] ì‹¤ì‹œê°„ ë­í‚¹ ë‰´ìŠ¤ (Start-up Dashboard)
# ==========================================
def get_ranking_news():
    print("â³ ì˜¤ëŠ˜ì˜ í†µí•© ë­í‚¹ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
    url = "https://news.naver.com/main/ranking/popularDay.naver"

    # ë¡œë´‡ì´ ì•„ë‹˜ì„ ì¦ëª…í•˜ê¸° ìœ„í•œ í—¤ë”
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}

    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        news_boxes = soup.select(".rankingnews_box")
        ranking_data = []

        count = 0
        for box in news_boxes:
            try:
                press_name = box.select_one(".rankingnews_name").text
                list_content = box.select(".list_content > a")

                for news in list_content[:1]: # ê° ì–¸ë¡ ì‚¬ë³„ 1ë“± ê¸°ì‚¬ë§Œ
                    title = news.text
                    link = news['href']
                    ranking_data.append([press_name, title, link])
                    count += 1
                if count >= 5: break
            except:
                continue

        return ranking_data
    except Exception as e:
        print(f"ë­í‚¹ ë¡œë”© ì—ëŸ¬: {e}")
        return []

# ==========================================
# 2. [í•µì‹¬ ê¸°ëŠ¥] ë¶„ì•¼ë³„ ë‰´ìŠ¤ ëª¨ì•„ë³´ê¸° (ê²½ì œ, IT ë“±)
# ==========================================
def get_category_news(code, category_name):
    print(f"\nğŸ“‚ '{category_name}' ë¶„ì•¼ì˜ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")

    # ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ URL
    url = f"https://news.naver.com/section/{code}"

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}

    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # ì„¹ì…˜ë³„ ë©”ì¸ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        articles = soup.select(".sa_text")
        news_data = []

        count = 0
        for article in articles:
            if count >= 10: break # ìƒìœ„ 10ê°œ ìˆ˜ì§‘

            try:
                title_tag = article.select_one(".sa_text_title")
                title = title_tag.text.strip()
                link = title_tag['href']

                # ìš”ì•½ë¬¸(ë¯¸ë¦¬ë³´ê¸°) ì¶”ì¶œ
                desc_tag = article.select_one(".sa_text_lede")
                desc = desc_tag.text.strip() if desc_tag else "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤."

                news_data.append({
                    "ìˆœìœ„": count + 1,
                    "ë¶„ë¥˜": category_name,
                    "ì–¸ë¡ ì‚¬": "ë„¤ì´ë²„ë‰´ìŠ¤",
                    "ì œëª©": title,
                    "ìš”ì•½": desc,
                    "ë§í¬": link
                })
                count += 1
            except:
                continue

        # ë§Œì•½ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹„ìƒ ë©”ì‹œì§€ ì¶œë ¥
        if not news_data:
            print("âš ï¸ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (HTML êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)")

        return news_data

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# ==========================================
# 3. ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥ í•¨ìˆ˜
# ==========================================
def save_and_print(data, filename_prefix):
    if not data:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(data)

    # í™”ë©´ ì¶œë ¥
    print("\n" + "="*60)
    print(f"ğŸ“¢ ìˆ˜ì§‘ ê²°ê³¼ (Top {len(df)})")
    print("="*60)

    # ê°€ë…ì„±ì„ ìœ„í•´ ì œëª©ê³¼ ìš”ì•½ ì•ë¶€ë¶„ë§Œ ì¶œë ¥
    for i in range(len(df)):
        print(f"[{i+1}] {df.iloc[i]['ì œëª©']}")
        print(f"    â””â”€ {df.iloc[i]['ìš”ì•½'][:50]}...")
        print()

    # íŒŒì¼ ì €ì¥ (CSV)
    filename = f"{filename_prefix}_{datetime.now().strftime('%H%M')}.csv"

    # ì—‘ì…€ í•œê¸€ ê¹¨ì§ ë°©ì§€(utf-8-sig)
    df.to_csv(filename, index=False, encoding='utf-8-sig')

    print(f"ğŸ’¾ '{filename}' íŒŒì¼ë¡œ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ì¤‘...")
    try:
        files.download(filename)
    except:
        print("(ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.)")

# ==========================================
# 4. ë©”ì¸ í”„ë¡œê·¸ë¨ (Menu)
# ==========================================
def main():
    print("="*60)
    print("ğŸ“°  Daily News Curator (ë¶„ì•¼ë³„ ë‰´ìŠ¤ íë ˆì´í„°)")
    print("="*60)

    # [1] í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ë­í‚¹ ë‰´ìŠ¤ ë³´ì—¬ì£¼ê¸°
    rankings = get_ranking_news()
    if rankings:
        print("\nğŸ”¥ [ì‹¤ì‹œê°„ ë§ì´ ë³¸ ë‰´ìŠ¤ Top 5]")
        for i, item in enumerate(rankings):
            print(f"{i+1}. {item[1]} ({item[0]})")
    else:
        print("\n(í˜„ì¬ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)")

    while True:
        print("\n" + "-"*60)
        print("ğŸ’¡ ê´€ì‹¬ ìˆëŠ” ë‰´ìŠ¤ ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ğŸ’° ê²½ì œ (ì¦ê¶Œ, ë¶€ë™ì‚°, ê¸ˆìœµ)")
        print("2. ğŸ“± IT/ê³¼í•™ (AI, í…Œí¬, ëª¨ë°”ì¼)")
        print("3. âš–ï¸ ì‚¬íšŒ (ì‚¬ê±´ì‚¬ê³ , êµìœ¡, ë…¸ë™)")
        print("4. ğŸ›ï¸ ì •ì¹˜ (í–‰ì •, êµ­íšŒ)")
        print("5. ğŸŒ ì„¸ê³„ (êµ­ì œ ì´ìŠˆ)")
        print("0. âŒ ì¢…ë£Œ")
        print("-"*60)

        choice = input(">>> ë²ˆí˜¸ ì…ë ¥: ")

        # ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ ì½”ë“œ ë§¤í•‘
        categories = {
            '1': ('101', 'ê²½ì œ'),
            '2': ('105', 'ITê³¼í•™'),
            '3': ('102', 'ì‚¬íšŒ'),
            '4': ('100', 'ì •ì¹˜'),
            '5': ('104', 'ì„¸ê³„')
        }

        if choice == '0':
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
            break

        elif choice in categories:
            code, name = categories[choice]
            # í•´ë‹¹ ë¶„ì•¼ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
            data = get_category_news(code, name)
            # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
            save_and_print(data, f"{name}_ë‰´ìŠ¤ëª¨ìŒ")

        else:
            print("âš ï¸ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()